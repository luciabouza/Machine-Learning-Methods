{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Implementación y análisis algoritmos ID3 y Random Forest\n",
    "\n",
    "### Grupo 21:\n",
    "     - Lucía Bouza  C.I 42897970\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta tarea es construir clasificadores basados en árboles de decisión y comparar la performance con las implementaciones de Scikit-learn sobre el conjunto de datos QSAR. \n",
    "\n",
    "la tarea se divide en 3 partes. La primera implementar el algoritmo ID3. Luego implementar Random Forest utilizando la implementación ID3 de la primera parte. Para finalizar, se propone comparar lo desarrollado con las implementaciones de Scikit-learn, jugando con los hiperparámetros de los métodos. \n",
    "\n",
    "Se medirá la performance de los diferentes métodos utilizando las métricas de accurancy, precisión, recall y F1.\n",
    "\n",
    "Para todas las implmentaciones se utilizará un conjunto de entrenamiento, uno de evaluación para ajuste de los parámetros, y luego uno de test, para determinar la performance final de los algoritmos. Se elige realizarlo de esta manera para evitar sobreajuste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "## 2.1 Preprocesamiento de datos\n",
    "\n",
    "El conjunto de datos QSAR está compuesto por 1024 atributos binarios de moléculas, clasificándolas en altamente tóxicas y no altamente tóxicas (clase de salida). Todos los datos de los atributos son numéricos, binarios, y no hay datos faltantes. \n",
    "La clase de salida tiene solamente dos valores (positive/negative)por lo que lo transformaremos en valores numéricos binarios dado que Scikit-learn solamente acepta atributos numéricos. \n",
    "\n",
    "Para realizar este cambio seguimos el ejemplo publicado, utilizando el ordinal encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "      <th>...</th>\n",
       "      <th>c1016</th>\n",
       "      <th>c1017</th>\n",
       "      <th>c1018</th>\n",
       "      <th>c1019</th>\n",
       "      <th>c1020</th>\n",
       "      <th>c1021</th>\n",
       "      <th>c1022</th>\n",
       "      <th>c1023</th>\n",
       "      <th>c1024</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1026 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c0  c1  c2  c3  c4  c5  c6  c7  c8  c9  ...  c1016  c1017  c1018  c1019  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0  ...      0      0      0      0   \n",
       "1   0   0   1   0   0   0   0   0   0   0  ...      0      0      0      0   \n",
       "2   0   0   0   0   0   0   0   0   0   0  ...      0      1      0      0   \n",
       "3   0   0   0   0   0   0   0   1   0   0  ...      0      0      0      0   \n",
       "4   0   0   0   0   0   0   0   0   0   0  ...      0      0      0      0   \n",
       "5   1   0   0   0   0   0   1   0   0   0  ...      0      0      0      0   \n",
       "6   0   0   0   0   0   0   0   0   0   0  ...      0      0      0      0   \n",
       "7   0   0   1   0   0   0   0   0   0   0  ...      0      0      1      0   \n",
       "8   0   0   0   0   0   0   0   0   0   0  ...      0      1      1      0   \n",
       "9   0   0   0   0   0   0   0   0   0   0  ...      0      0      0      0   \n",
       "\n",
       "   c1020  c1021  c1022  c1023     c1024  output  \n",
       "0      0      0      0      0  negative     0.0  \n",
       "1      0      0      0      0  negative     0.0  \n",
       "2      0      0      0      0  negative     0.0  \n",
       "3      0      0      0      0  negative     0.0  \n",
       "4      0      0      0      0  negative     0.0  \n",
       "5      1      0      0      0  negative     0.0  \n",
       "6      0      0      0      0  negative     0.0  \n",
       "7      0      0      0      0  positive     1.0  \n",
       "8      0      0      0      0  negative     0.0  \n",
       "9      0      0      0      0  negative     0.0  \n",
       "\n",
       "[10 rows x 1026 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing, model_selection, tree, metrics, utils\n",
    "import pandas as pd\n",
    "\n",
    "#Carga de Datos\n",
    "dataset = pd.read_csv('qsar_oral_toxicity.csv', sep=';', prefix='c',header=None)\n",
    "\n",
    "#preprocesamiento\n",
    "# creamos un codificador \"ordinal\" y lo ajustamos a la columna 1024 \n",
    "enc = preprocessing.OrdinalEncoder()\n",
    "enc.fit(dataset[['c1024']])\n",
    "\n",
    "#transformamos la columna 1024 y la guardamos en una nueva columna\n",
    "dataset['output']  = enc.transform(dataset[['c1024']])\n",
    "\n",
    "#vemos las 10 primeras filas para observar resultado\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego creamos los conjuntos de entrenamiento, validación y test. Se determina que el conjunto de test sea un 20% del Dataset inicial, el conjunto de validación un 16% (20% del conjunto de trainAux) y el conjunto de entrenamiento un 64% del Dataset de inicio. Dado que las clases de salida se encuentran muy desbalanceadas, se determina utilizar estratificación para asegurarnos que tendremos la misma proporción de ambas clases en todos los conjuntos. También se determina no utilizar una semilla (variable random_state), para que los datasets sean diferentes para cada ejecución. \n",
    "\n",
    "Para realizar los diferentes conjuntos, ejecutamos el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos conjuntos entrenamiento, validación y test (entrenamiento 64%, validación 16%, test 20%)\n",
    "\n",
    "#trainAux, test = model_selection.train_test_split(dataset, test_size=0.2)\n",
    "trainAux, test = model_selection.train_test_split(dataset, stratify=dataset['output'], test_size=0.2)\n",
    "\n",
    "#creamos conjuntos entrenamiento y validacion (entrenamiento 80%, validacion 20%) a partir del 80% de train\n",
    "train, validation = model_selection.train_test_split(trainAux, stratify=trainAux['output'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2.2 Algoritmos\n",
    "\n",
    "Consideraciones para ambos algoritmos:\n",
    "\n",
    "Si bien sabemos que nuestro dataset está compuesto de valores binarios, se implementaron los algoritmos para que los atributos de entrada puedan tomar cualquier valor numérico. En un principio se habían hecho ajustes para mejorar los tiempos de ejecución asumiendo que los atributos tomaban solamente valores 0 y 1. Luego se decidió sacrificar estas mejoras en pos de tener un algoritmo más genérico y funcional en diferentes datasets. \n",
    "\n",
    "Un cambio importante que debió realizarse fue generar una estructura con los posibles valores de todos los atributos previo a la creación de los árboles. Esto no puede realizarse a la interna del algoritmo de creación del árbol ya que el dataset con el que se trabaja se va particionando. En un momento dado puede darse que en mi dataset de ejemplos falte algún valor del atributo que estoy evaluando, pero igualmente para ese valor es necesario hacer una hoja en el árbol. Si solamente considero los valores que tiene mi atributo en el dataset que estoy trabajando en la recursión, puedo estar perdiéndome estos casos y no estar generando el arbol completo. \n",
    "\n",
    "\n",
    "Algoritmo ID3:\n",
    "\n",
    "Se implementa el algoritmo ID3 descrito en la página 53 del libro de Tom Mitchell e implementándose podas. Se agrega  la posibilidad de poder elegir la máxima cantidad de atributos a evaluar en cada nodo. Si queremos ejecutar el algoritmo ID3 tradicional, en esa variable ponemos la cantidad total de atributos. Sino, podemos colocar el valor que deseemos. Esto nos permite utilizar esta implementación para Random Forest.\n",
    "\n",
    "Las podas implementadas son dos. La primera poda el árbol y coloca una hoja con el valor más común de la salida cuando no tengo más de 10 datos de ejemplo. La segunda se aplica luego de calcular la ganancia para los atributos (IG). si todos los atributos me dan ganancia cero, entonces hago una hoja con el valor de salida más común para los datos. \n",
    "\n",
    "La estructura utilizada para representar un árbol está compuesta de un valor entero (Raiz) y una lista de árboles que respresentan las ramas de dicha raiz. \n",
    "\n",
    "A continuación se presenta el pseudocódigo del algoritmo:\n",
    "\n",
    "```python\n",
    "    def ID3(Datos,targetAttribute, Atributos, ValsAtributos, maxAtributos):\n",
    "    Arb = Arbol()\n",
    "    \n",
    "    #si todos los valores son iguales, devuelvo ese valor\n",
    "    Arb.valor = unico Valor\n",
    "    \n",
    "    #si no hay atributos, retorno el valor mas comun del atributo objetivo para los datos o  \n",
    "    # si ejemplos en Datos es menor que 10 (Poda implementada)\n",
    "    Arb.valor = valor con más ocurrencias\n",
    "    \n",
    "    else:\n",
    "        #seleccionar randómicamente maxAtributos de la lista de Atributos. si tengo menos Atributos que maxAtributos, elijo todos\n",
    "        subSetAtributos = selección randómica\n",
    "         \n",
    "        #seleccionar el mejor atributo, calculando IG para todos los aributos\n",
    "        Atributo = Atributo con más IG de subSetAtributos\n",
    "        \n",
    "        # si IG máximo es 0, retorno el valor mas comun del atributo objetivo para los datos (Poda implementada)\n",
    "        Arb.valor = valor con más ocurrencias\n",
    "        \n",
    "        #Si no:\n",
    "            #Coloco en la raiz Atributo   \n",
    "            Arb.valor = Atributo\n",
    "\n",
    "            #elimino el atributo de la lista\n",
    "            Atributos = Atributos - Atributo\n",
    "\n",
    "            #Por cada valor posible del Atributo\n",
    "            for i in ValoresAtributo    \n",
    "                # si no hay datos con ese valor, coloco hoja con el valor mas comun de la salida para los datos. \n",
    "                    Hoja = Arbol()\n",
    "                    Hoja.valor = valor con más ocurrencias\n",
    "                    Arb.Ramas.insert(i,Hoja)\n",
    "                #sino, llamo recursivo\n",
    "                else:\n",
    "                    Arb.Ramas.insert(i, ID3(Ejemplos, targetAttribute, Atributos, ValsAtributos, maxAtributos))      \n",
    "    return Arb\n",
    "```\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "La implementación del algoritmo de Random Forest se realiza de acuerdo al siguiente pseudocódigo, donde se puede elegir la cantidad de árboles que se desean hacer, la cantidad de ejemplos a tomar para la generación de cada árbol y la cantidad de atributos a evaluar en cada nodo del árbol. En el algoritmo se llama a la implementación de ID3 anterior. La estructura utilizada para la representación del Random Forest es una lista de árboles. \n",
    "\n",
    "```python\n",
    "    def RandomForest(Datos, targetAttribute, Atributos, CantArboles, CantAtributos, CantElementos):\n",
    "    ListaArboles = []\n",
    "       \n",
    "    for i in range(CantArboles):\n",
    "        #DatasetArbol = Genero DatasetArbol con CantElementos, tomando de forma uniforme de Datos\n",
    "\n",
    "        #ArbolDecision = llamo a ID3 con el DatasetArbol, los Atributos y la cantAtributos a evaluar en cada nodo\n",
    "        \n",
    "        #inserto ArbolDecision en ListaArboles\n",
    "        \n",
    "    return ListaArboles\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Evaluación\n",
    "\n",
    "Se utilizan las métricas: accurancy, precisión, recall y F1. \n",
    "Se decide utilizar métricas adicionales a accurancy ya que la clasificación de las moléculas se encuentra desbalanceada: 741 valores positivos y 8251 valores negativos. \n",
    "\n",
    "Precisión y Recuperación nos ayudan a determinar el comportamiento para cada clase de salida.\n",
    "La precisión mide qué tan bueno es el clasificador cuando dice que un ejemplo es de una determinada clase, mientras que la recuperación mide qué proporción encuentra de los elementos de una clase existentes. La medida-F es la media armónica entre precisión y recall, e intenta combinar ambas en un sólo número. tomaremos F con $\\beta$ = 1. \n",
    "\n",
    "Calcularemos precisión, recall y F1 para la clase positiva y la negativa, ya que nos interesa poder ver la perfomance que se tiene en ambas clases.\n",
    "\n",
    "El cálculo de las métricas se realiza manualmente y no con los métodos de Scikit-learn, ya que en un principio se asumió que no se podían utilizar, y al momento que se dijo que si ya se encontraba implementada la evaluación. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.1 Resultados algoritmos implementados\n",
    "\n",
    "Se presentarán a continuación los resultados de las implementaciones A y B contra el conjunto de validación, con diferentes valores de las variables para evaluar los diferentes resultados. En esta tabla se presentan los resultados utilizando una implementación preliminar de ID3 sin podas.\n",
    "\n",
    "También se presenta una segunda implementación de Random Forest, que la identificamos como Random Forest híbrido. Esta implementación utiliza el mismo algoritmo Random Forest descrito en el inciso anterior, pero con la salvedad que utiliza la implementación de Scikit-learn para construir los árboles de decisión. Se decide explorar este caso, porque al realizar las pruebas de los algoritmos implementados, notamos que la performance de Random Forest era peor que la de ID3. Se decidió realizar esta prueba para observar empíricamente si al utilizar un algoritmo que cree árboles más performantes, el Random Forest implementado era también más performante. Aquí presentaremos los resultados, las conclusiones se verán en el último inciso del documento.  \n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th># Árboles</th>\n",
    "    <th># Ejemplos</th> \n",
    "    <th># Atributos</th>\n",
    "    <th>Accurancy</th>\n",
    "    <th>Precisión 1</th>\n",
    "    <th>Recall 1</th>\n",
    "    <th>F1 1</th>\n",
    "    <th>Precisión 0</th>\n",
    "    <th>Recall 0</th>\n",
    "    <th>F1 0</th>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0,28</td>\n",
    "    <td>0,10</td>\n",
    "    <td>0,15</td>\n",
    "    <td>0,92</td>\n",
    "    <td>0,97</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>800</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0.05</td>\n",
    "    <td>0.008</td>\n",
    "    <td>0.01</td>\n",
    "    <td>0,92</td>\n",
    "    <td>0,98</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>4000</td>\n",
    "    <td>900</td>\n",
    "    <td>0,91</td>\n",
    "    <td>0,11</td>\n",
    "    <td>0,02</td>\n",
    "    <td>0,03</td>\n",
    "    <td>0,92</td>\n",
    "    <td>0,99</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>   \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.003</td>\n",
    "    <td>0.03</td>\n",
    "    <td>0.01</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.64</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>5000</td>\n",
    "    <td>200</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.003</td>\n",
    "    <td>0.04</td>\n",
    "    <td>0.007</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.64</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>200</td>\n",
    "    <td>2000</td>\n",
    "    <td>100</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.02</td>\n",
    "    <td>0.004</td>\n",
    "    <td>0.004</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.47</td>\n",
    "    <td>0.62</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>800</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.001</td>\n",
    "    <td>0.02</td>\n",
    "    <td>0.003</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.48</td>\n",
    "    <td>0.63</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>900</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.002</td>\n",
    "    <td>0.02</td>\n",
    "    <td>0.004</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.65</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>RFHibrido</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.74</td>\n",
    "    <td>0.39</td>\n",
    "    <td>0.51</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 1 - Comparación algoritmos ID3 y Random Forest implementados</caption>\n",
    "</table>\n",
    "\n",
    "Observamos que el mejor desempeño para las pruebas realizadas se da con ID3, considerando todos los ejemplos de entrenamiento y todos los atributos. Para Random Forest, los mejores resultados se obtienen con 100 árboles, 400 atributos evaluados por árbol y 4000 ejemplos tomados por árbol. \n",
    "\n",
    "Dado que los algoritmos implementados tienen muy mala performance en la clase positiva, se decide realizar modificaciones al algoritmo ID3, agregando las dos podas explicadas en el inciso 2.2. Esto mejoró notablemente los tiempos de ejecución y los resultados. A continuación presentamos los resultados de las pruebas realizadas tras el cambio en el algoritmo:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th># Árboles</th>\n",
    "    <th># Ejemplos</th> \n",
    "    <th># Atributos</th>\n",
    "    <th>Accurancy</th>\n",
    "    <th>Precisión 1</th>\n",
    "    <th>Recall 1</th>\n",
    "    <th>F1 1</th>\n",
    "    <th>Precisión 0</th>\n",
    "    <th>Recall 0</th>\n",
    "    <th>F1 0</th>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>800</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0.41</td>\n",
    "    <td>0.32</td>\n",
    "    <td>0.36</td>\n",
    "    <td>0,94</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>4000</td>\n",
    "    <td>900</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0,39</td>\n",
    "    <td>0,39</td>\n",
    "    <td>0,39</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>   \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.41</td>\n",
    "    <td>0.44</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>200</td>\n",
    "    <td>5000</td>\n",
    "    <td>100</td>\n",
    "    <td>0.89</td>\n",
    "    <td>0.41</td>\n",
    "    <td>0.35</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>200</td>\n",
    "    <td>2000</td>\n",
    "    <td>100</td>\n",
    "    <td>0.89</td>\n",
    "    <td>0.39</td>\n",
    "    <td>0.29</td>\n",
    "    <td>0.33</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.93</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>800</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.43</td>\n",
    "    <td>0.35</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>900</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 2 - Comparación algoritmos ID3 con Podas y Random Forest</caption>\n",
    "</table>\n",
    "\n",
    "Luego de haber detectado los hiperparámetros que mejor funcionan para cada algoritmo, se ejecuta contra el conjunto de Test, obteniéndose los siguientes resultados:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th># Árboles</th>\n",
    "    <th># Ejemplos</th> \n",
    "    <th># Atributos</th>\n",
    "    <th>Accurancy</th>\n",
    "    <th>Precisión 1</th>\n",
    "    <th>Recall 1</th>\n",
    "    <th>F1 1</th>\n",
    "    <th>Precisión 0</th>\n",
    "    <th>Recall 0</th>\n",
    "    <th>F1 0</th>\n",
    "  </tr>\n",
    " <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>0,92</td>\n",
    "    <td>0,52</td>\n",
    "    <td>0,47</td>\n",
    "    <td>0,50</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,96</td>\n",
    "    <td>0,96</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>RF</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.40</td>\n",
    "    <td>0.43</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 3 - Resultados ID3 con Podas y Random Forest contra conjunto de test</caption>\n",
    "</table>\n",
    "\n",
    "Los resultados son similares a los obtenidos contra el conjunto de evaluación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 Experimentación con Scikit Learn\n",
    "\n",
    "Se presentarán a continuación los resultados de las implementaciones de Scikit-learn para ID3 y Random Forest, variando algunos de los hiperparámetros. Cabe destacar que muchas de las variables que se pueden modificar no están implementadas en nuestro algoritmo. Realizamos estas pruebas adicionales para experimentar con la librería y comparar entre las diferentes variantes de Scikit-learn, más que para compararlo con nuestra implementación.   \n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th>Criterio</th>\n",
    "    <th># Árboles</th>\n",
    "    <th># Ejemplos por árbol</th> \n",
    "    <th># Atributos</th>\n",
    "    <th>Balance de Clases</th>\n",
    "    <th>Accurancy</th>\n",
    "    <th>Precisión 1</th>\n",
    "    <th>Recall 1</th>\n",
    "    <th>F1 1</th>\n",
    "    <th>Precisión 0</th>\n",
    "    <th>Recall 0</th>\n",
    "    <th>F1 0</th>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>No</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.47</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.49</td>\n",
    "    <td>0.96</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.95</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>800</td>\n",
    "    <td>No</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.47</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.48</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>balanced</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.95</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>ID3</td>\n",
    "    <td>Gini</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>No</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.55</td>\n",
    "    <td>0.53</td>\n",
    "    <td>0.96</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.96</td>\n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>1000</td>\n",
    "    <td>400</td>\n",
    "    <td>No</td>\n",
    "    <td>0.92</td>\n",
    "    <td>0.67</td>\n",
    "    <td>0.24</td>\n",
    "    <td>0.35</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>200</td>\n",
    "    <td>1000</td>\n",
    "    <td>400</td>\n",
    "    <td>No</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.74</td>\n",
    "    <td>0.24</td>\n",
    "    <td>0.36</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.97</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>No</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.76</td>\n",
    "    <td>0.42</td>\n",
    "    <td>0.54</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.97</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>Balanced</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.73</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.56</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.97</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>Balanced subsample</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.71</td>\n",
    "    <td>0.43</td>\n",
    "    <td>0.54</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.97</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>1000</td>\n",
    "    <td>800</td>\n",
    "    <td>No</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.74</td>\n",
    "    <td>0.30</td>\n",
    "    <td>0.43</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>100</td>\n",
    "    <td>1000</td>\n",
    "    <td>200</td>\n",
    "    <td>No</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.79</td>\n",
    "    <td>0.25</td>\n",
    "    <td>0.38</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Entropía</td>\n",
    "    <td>200</td>\n",
    "    <td>4000</td>\n",
    "    <td>800</td>\n",
    "    <td>No</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.71</td>\n",
    "    <td>0.33</td>\n",
    "    <td>0.45</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Gini</td>\n",
    "    <td>100</td>\n",
    "    <td>1000</td>\n",
    "    <td>400</td>\n",
    "    <td>No</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.67</td>\n",
    "    <td>0.18</td>\n",
    "    <td>0.28</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF</td>\n",
    "    <td>Gini</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>No</td>\n",
    "    <td>0.93</td>\n",
    "    <td>0.79</td>\n",
    "    <td>0.41</td>\n",
    "    <td>0.54</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.99</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "    <caption>Tabla 4 - Comparación algoritmos ID3 y Random Forest de Scikit-learn</caption>\n",
    "</table>\n",
    "\n",
    "Observando la tabla vemos que para todos los casos el algoritmo tiene peor performance para detectar los casos positivos. Esto se da por la naturaleza del dataset, donde una gran proporción de los ejemplos son de clase negativa en la salida. Aún cuando utilizamos la funcionalidad del balance de clases, los resultados no mejoran significativamente. \n",
    "\n",
    "Observamos que el mejor desempeño para las pruebas realizadas se da con Random Forest, con 100 árboles, 400 atributos evaluados por árbol y 4000 ejemplos tomados por árbol, utilizando la métrica de entropía para la selección de atributos. \n",
    "\n",
    "Los tiempos de ejecución de estos métodos son del orden de los milisegundos, mientras que las implementaciones realizadas son del orden de minutos para ID3, y horas para Random Forest. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.3 Comparación resultados\n",
    "\n",
    "Se presentarán a continuación los mejores resultados de las implementaciones A y B, junto con los mejores resultados de Scikit learn. Para todos los casos el criterio de elección de atributos para la construcción del árbol es entropía.  \n",
    "\n",
    "\n",
    "<table>\n",
    "   <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th># Árboles</th>\n",
    "    <th># Ejemplos por árbol</th> \n",
    "    <th># Atributos</th>\n",
    "    <th>Accurancy</th>\n",
    "    <th>Precisión 1</th>\n",
    "    <th>Recall 1</th>\n",
    "    <th>F1 1</th>\n",
    "    <th>Precisión 0</th>\n",
    "    <th>Recall 0</th>\n",
    "    <th>F1 0</th>\n",
    "  </tr>\n",
    " <tr>\n",
    "    <td>ID3 c/podas</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>0,90</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,41</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "    <td>0,95</td>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>RF c/ID3 podas</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.41</td>\n",
    "    <td>0.44</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RF Balanced Scikit</td>\n",
    "    <td>100</td>\n",
    "    <td>4000</td>\n",
    "    <td>400</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.73</td>\n",
    "    <td>0.46</td>\n",
    "    <td>0.56</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.97</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>ID3 Scikit</td>\n",
    "    <td>N/A</td>\n",
    "    <td>|train|</td>\n",
    "    <td>todos</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.47</td>\n",
    "    <td>0.50</td>\n",
    "    <td>0.49</td>\n",
    "    <td>0.96</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.95</td>\n",
    "  </tr> \n",
    "    <caption>Tabla 5 - Comparación algoritmos implementados contra Scikit Learn</caption>\n",
    "</table>\n",
    "\n",
    "Podemos observar que si bien la performance de los algoritmos Scikit-learn es mejor, se da que tanto para los algoritmos implementados como para los de Scikit-learn, los hiperparámetros que mejor funcionan son los mismos. \n",
    "\n",
    "En el caso de ID3, se da lo que se esperaba, y es un mejor rendimiento cuando se utiliza todo el conjunto de entrenamiento y se evalúan todos los atributos.\n",
    "\n",
    "En el caso de Random Forest los hiperparámetros que dan mejores resultados es la construcción de 100 árboles, donde se evalúan en cada uno 400 atributos y se utilizan 4000 ejemplos de entrenamiento elegidos de forma randómica, tanto atributos como ejemplos. \n",
    "\n",
    "La performance de la implementación de Scikit es mejor, sobre todo en la clase de los positivos para Random Forest. Para ID3 la implementación de nuestro algoritmo se acerca bastante a la performance del de Scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Ejecución de ID3\n",
    "\n",
    "Aquí se da la posibilidad de ejecutar la implementación del algoritmo ID3. Se permite elegir la cantidad de máxima de atributos a evaluar en cada nodo y la cantidad de ejemplos a utilizar para poder correrlo en menor tiempo. Si se desea evaluar contra el conjunto de validación, cambiar test por validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy: 0.9216231239577543\n",
      "ejemplos positivos: 148\n",
      "ejemplos positivos acertados: 70\n",
      "Precision 1: 0.5263157894736842\n",
      "Recall 1: 0.47297297297297297\n",
      "F1 1: 0.498220640569395\n",
      "ejemplos Negativos: 1651\n",
      "ejemplos Negativos acertados: 1588\n",
      "Precision 0: 0.9531812725090036\n",
      "Recall 0: 0.9618413082980012\n",
      "F1 0: 0.9574917093759421\n"
     ]
    }
   ],
   "source": [
    "import ID3\n",
    "\n",
    "# Aqui se pueden modificar los parámetros para ejecutar ID3\n",
    "CantidadAtributos = 1024\n",
    "CantidadEjemplos = train.shape[0]\n",
    "\n",
    "ID3.CreacionYEvaluacionID3(dataset, train, test, CantidadEjemplos, CantidadAtributos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Ejecución de Random Forest\n",
    "\n",
    "Aquí se da la posibilidad de ejecutar la implementación del algoritmo Random Forest. Se permite elegir la cantidad máxima de atributos a evaluar en cada nodo, la cantidad de ejemplos a utilizar para la generación de cada árbol y la cantidad de árboles a generar. Si se desea evaluar contra el conjunto de validación, cambiar test por validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy: 0.9043913285158421\n",
      "ejemplos positivos: 148\n",
      "ejemplos positivos acertados: 74\n",
      "Precision 1: 0.4625\n",
      "Recall 1: 0.4088397790055249\n",
      "F1 1: 0.43401759530791795\n",
      "ejemplos Negativos: 1651\n",
      "ejemplos Negativos acertados: 1638\n",
      "Precision 0: 0.9386819484240687\n",
      "Recall 0: 0.9501160092807425\n",
      "F1 0: 0.9443643701354857\n"
     ]
    }
   ],
   "source": [
    "import RandForest\n",
    "\n",
    "# Aqui se pueden modificar los parámetros para ejecutar Random Forest\n",
    "CantArboles= 100\n",
    "CantAtributos= 400\n",
    "CantElementos = 4000\n",
    "\n",
    "RandForest.CreacionYEvaluacionRandomForest(dataset, train, test, CantArboles, CantAtributos, CantElementos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la implementación de este laboratorio, se pueden comprobar de forma empírica algunos de los conceptos estudiados en el teórico.\n",
    "\n",
    "Con respecto a las métricas:\n",
    "Si bien en primera instancia al obtener la métrica de accurancy se puede presuponer que el algoritmo funciona realmente bien, es importante conocer la naturaleza de nuestro dataset ya que podríamos estar engañándonos. \n",
    "Para el caso del dataset QSAR, los resultados de salida se encuetran muy desbalanceados. Cuando generamos los clasificadores, sea Random Forest o ID3, encontramos que tiene una altísima precisión para los casos más abundantes (cuando la molécula no es altamente tóxica), pero muy baja para los casos positivos (cuando la molécula es altamente tóxica). \n",
    "Esto quiere decir que la gran mayoría de las veces clasifico a las moléculas como no tóxicas, y estoy en lo cierto la gran mayoría de las veces porque los ejemplos son casi todos de este tipo; pero el algoritmo tiene muy poca capacidad para detectar las moléculas altamente tóxicas, que seguramente sea el dato más interesante. \n",
    "\n",
    "Es por eso que importa tener las métricas de Precisión, Recall y F1 para las diferentes clases, ya que nos da un mejor entendimiento de la performance de los algoritmos.\n",
    "\n",
    "Con respecto a los algoritmos:\n",
    "Notamos que la performance en detectar las clases positivas siempre es muchísimo más baja que para detectar las negativas, independientemente del algoritmo y los parámetros utilizados. \n",
    "También notamos que la performance de los algoritmos de SciKit learn es mejor que la de los algoritmos implementados. Con esto nos referimos a la performance en la clasificación de objetos, pero también cabe destacar que los tiempos de respuesta son de ordenes mucho más bajos que los desarrollados.\n",
    "\n",
    "Comparando los diferentes algoritmos para las implementaciones de Scikit learn, vemos que Random Forest tiene mejor performance que ID3. Encontramos que mejora al tomar mayor cantidad de ejemplos para entrenar cada árbol, y que la cantidad de atributos tomados para construir cada árbol, no impacta tan significativamente.\n",
    "\n",
    "En el caso de nuestra implementación, el algoritmo ID3 sin podas se comporta mejor que Random Forest. Suponíamos que el mal comportamiento de Random Forest se debía a que ID3 tiene baja performance en la clase positiva, dada la naturaleza desbalanceada del dataset. Al utilizarlo repetidas veces para la creación de los árboles en RF, y luego aplicar votación entre los árboles para clasificar, el error se ve intensificado y afecta en mayor proporción a Random Forest. Fue por esta razón que se optó realizar el experimento del Random Forest híbrido, obteniendo resultados similares al Random Forest de Scikit-learn, por lo que la suposición parecería ser correcta. \n",
    "\n",
    "Al tener nuestros algoritmos muy mala performance en la clase positiva, y al haber detectado que el problema radicaba en ID3, se decidió implementar podas para evitar sobreajuste. Al realizar las pruebas se vió que esto mejoraba notablemente la performance tanto de ID3 como de Random Forest, ID3 alcanzando valores similares a la implementación de Scikit-learn, y Random Forest acercándose muchísimo en comparación a su antigua implementación. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
